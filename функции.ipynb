{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0b5ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для методов понижения размерности\n",
    "\n",
    "def reduce_dims(df, dims=2, method='pca', perplexity=30):\n",
    "    \n",
    "    assert method in ['pca', 'tsne'], 'Неверно указан метод'\n",
    "    \n",
    "    if method=='pca':\n",
    "        dim_reducer = PCA(n_components=dims, random_state=42)\n",
    "        components = dim_reducer.fit_transform(df)\n",
    "    elif method == 'tsne':\n",
    "        dim_reducer = TSNE(n_components=dims, learning_rate=250, random_state=42, perplexity=perplexity)\n",
    "        components = dim_reducer.fit_transform(df)\n",
    "    else:\n",
    "        print('Error')\n",
    "        \n",
    "    colnames = ['component_' + str(i) for i in range(1, dims+1)]\n",
    "    return dim_reducer, pd.DataFrame(data = components, columns = colnames) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c413f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функции для отрисовки 2D и 3D-графиков\n",
    "\n",
    "def display_components_in_2D_space(components_df, labels=None):\n",
    "    components_with_labels_df = pd.concat([components_df, pd.DataFrame(labels)], axis=1)\n",
    "\n",
    "    figsize = (10, 7)\n",
    "    if labels is not None:\n",
    "        components_with_labels_df.plot(kind='scatter', x='component_1', y='component_2', \n",
    "                                         c=components_with_labels_df.iloc[:, -1], cmap=plt.get_cmap('jet'),\n",
    "                                         alpha=0.5, figsize=figsize)\n",
    "    else:\n",
    "        components_with_labels_df.plot(kind='scatter', x='component_1', y='component_2', alpha=0.5, figsize=figsize)\n",
    "\n",
    "    plt.xlabel('component_1')\n",
    "    plt.ylabel('component_2')\n",
    "    plt.title('2D mapping of objects')    \n",
    "    plt.show()\n",
    "\n",
    "def display_components_in_3D_space(components_df, labels=None):\n",
    "    components_with_labels_df = pd.concat([components_df, pd.DataFrame(labels)], axis=1)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    if labels is not None:\n",
    "        ax.scatter(components_with_labels_df['component_1'], \n",
    "                   components_with_labels_df['component_2'], \n",
    "                   components_with_labels_df['component_3'], \n",
    "                   c=components_with_labels_df.iloc[:, -1], \n",
    "                   cmap=plt.get_cmap('jet'), alpha=0.5)\n",
    "    else:\n",
    "        ax.scatter(components_with_labels_df['component_1'], \n",
    "                   components_with_labels_df['component_2'], \n",
    "                   components_with_labels_df['component_3'], \n",
    "                   alpha=0.5)\n",
    "\n",
    "    ax.set_xlabel('component_1')\n",
    "    ax.set_ylabel('component_2')\n",
    "    ax.set_zlabel('component_3')\n",
    "    plt.title('3D mapping of objects')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5add7a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_elbow_method(X):\n",
    "    \"\"\"Визуализация для метода 'локтя'\"\"\"\n",
    "    \n",
    "    distortions = []\n",
    "    K = range(2,30)\n",
    "    for k in K:\n",
    "        kmeanModel = KMeans(n_clusters=k, random_state=33).fit(X)\n",
    "        distortions.append(sum(np.min(cdist(X, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / X.shape[0])\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(K, distortions, 'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.title('The Elbow Method showing the optimal k')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e92432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_clusters_distribution(unique_labels, labels_counts):\n",
    "    \"\"\"Визуализация распределения классов по кластерам\"\"\"\n",
    "    plt.figure(figsize=(8,5))\n",
    "\n",
    "    plt.bar(unique, counts)\n",
    "\n",
    "    plt.xlabel('Clusters')\n",
    "    plt.xticks(unique)\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Clusters distribution')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41eab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# подсчет метрик и отрисовка модели\n",
    "\n",
    "def evaluate_preds(true_values, pred_values):\n",
    "    print(\"R2:\\t\" + str(round(r2(true_values, pred_values), 3)) + \"\\n\" +\n",
    "          \"MAE:\\t\" + str(round(mae(true_values, pred_values), 3)) + \"\\n\" +\n",
    "          \"MSE:\\t\" + str(round(mse(true_values, pred_values), 3)))\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    sns.scatterplot(x=pred_values, y=true_values)\n",
    "    \n",
    "    plt.xlabel('Predicted values')\n",
    "    plt.ylabel('True values')\n",
    "    plt.title('True vs Predicted values')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ddfc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция снижения использования памяти\n",
    "\n",
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.\n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f'Memory usage of dataframe is {start_mem:.2f} MB')\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f'Memory usage after optimization is: {end_mem:.2f} MB')\n",
    "    print(f'Decreased by {(100 * (start_mem - end_mem) / start_mem):.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ae1924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для поиска сочетания наилучшего количества кластеров и бачей\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "# vc = двумерные координаты\n",
    "\n",
    "X = np.zeros((len(vc), 2), dtype = int)\n",
    "X[:,0] = [x for x in vc]    \n",
    "ver = []\n",
    "\n",
    "silhouette = []\n",
    "\n",
    "clusters_range = range(3, 6)\n",
    "batch_range = range(2, int(len(X)/2))\n",
    "for n_clusters in (clusters_range):\n",
    "    for batch in (batch_range):\n",
    "        silhouette_avg = 0\n",
    "        try:\n",
    "            clusterer = MiniBatchKMeans(batch_size=batch, compute_labels=True, init='k-means++', init_size=None, max_iter=10, tol=0.0001, max_no_improvement=10, n_clusters=n_clusters, random_state=random_state, n_init=n_clusters, reassignment_ratio=0.05, verbose=0)\n",
    "            cluster_labels = clusterer.fit_predict(X)\n",
    "            silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "            silhouette.append(silhouette_avg)    \n",
    "        except:\n",
    "            pass\n",
    "        ver.append([silhouette_avg, n_clusters, batch])            \n",
    "ver = pd.DataFrame(ver, columns = ['silhouette_avg', 'n_clusters', 'batch'])\n",
    "ver = ver.drop_duplicates(['silhouette_avg', 'n_clusters'], keep='first').reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "ind = ver[ver['silhouette_avg'] >= np.mean(ver['silhouette_avg'])].index\n",
    "ver['cls'] = 0; ver.loc[ind, 'cls'] = 1\n",
    "ver = ver[ver['cls'] == 1].reset_index(drop=True)\n",
    "ver = ver[ver['n_clusters'] == np.min(ver['n_clusters'])].reset_index(drop=True)\n",
    "clusterer = MiniBatchKMeans(batch_size=ver.loc[0, 'batch'], compute_labels=True, init='k-means++', init_size=None, max_iter=10, tol=0.0001, max_no_improvement=10, n_clusters=ver.loc[0, 'n_clusters'], random_state=random_state, n_init=n_clusters, reassignment_ratio=0.05, verbose=0)\n",
    "labels_M = clusterer.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4ff7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция построения дендрограммы для модели агломеративной кластеризации \n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram\n",
    "\n",
    "\n",
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack([model.children_, model.distances_,\n",
    "                                      counts]).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    dendrogram(linkage_matrix, **kwargs)\n",
    "    \n",
    "    \n",
    "    \n",
    "# # setting distance_threshold=0 ensures we compute the full tree.\n",
    "# model = AgglomerativeClustering(distance_threshold=0, n_clusters=None)\n",
    "\n",
    "# model = model.fit(X_train_scaled)\n",
    "# plt.figure(figsize=(15, 10))\n",
    "# plt.title('Hierarchical Clustering Dendrogram')\n",
    "# # plot the top three levels of the dendrogram\n",
    "# plot_dendrogram(model, truncate_mode='level', p=3)\n",
    "# plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
